<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Performance study of HEP data analysis tools</title>
  <link rel="stylesheet" href="poster.css">
  <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1">
  <!-- Based on a poster template from https://github.com/cpitclaudel/academic-poster-template -->

  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link
    href="https://fonts.googleapis.com/css2?family=Fira+Sans+Condensed:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&amp;family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap"
    rel="stylesheet">

  <style type="text/css">
    html {
      font-size: 1.15rem
    }
  </style>
</head>

<body vocab="http://schema.org/" typeof="ScholarlyArticle">
  <header role="banner">
    <aside>
      <!-- <a href="https://github.com/cpitclaudel/academic-poster-template"><img src="logo.svg" alt="Tutorial logo"></a> -->
    </aside>
    <div>
      <h1 property="headline">Performance study of HEP data analysis tools</h1>
      <h2 property="alternativeHeadline">
        Project carried out at INFN-Sezione di Bari (June - August 2022) 
        as part of the DOE-INFN Summer Exchange Program 2022
      </h2>
      <address>
        <a property="author">Dung Hoang<sup>a</sup></a><a property="author">, Adriano Di Florio<sup>b, d</sup></a></a><a
          property="author">, Alexis Pompili<sup>b, c</sup></a></a><a property="author">, Umit Sozbilir<sup>b,
            c</sup></a></a><a property="author">, Vincenzo Mastrapasqua<sup>b, c</sup></a>
        <br /> <sup>a</sup><a property="sourceOrganization">Rhodes College,&nbsp</a><sup>b</sup><a
          property="sourceOrganization">INFN-Bari,&nbsp</a><sup>c</sup><a property="sourceOrganization">Università degli
          studi di Bari Aldo Moro,&nbsp</a><sup>d</sup><a property="sourceOrganization">Politecnico di Bari</a>
      </address>
      <span class="publication-info">
        <span property="publisher">Unpublished</span>,
        <time pubdate property="datePublished" datetime="2020-09-08">September 8, 2020</time>
      </span>
    </div>
    <aside>
      <!-- <a href="https://csail.mit.edu"><img style="background: white" src="csail.png" alt="MIT CSAIL Logo"></a> -->
    </aside>
  </header>

  <main property="articleBody">
    <article property="abstract">
      <header>
        <h3>Introduction</h3>
      </header>

      <p>
        The Python programming language is currently characterized by an enormous and rapidly growing “ecosystem” of software tools that adequately supports the analysis and visualization of “Big Data” like those large datasets collected by ongoing High Energy Physics big experiments. These tools and libraries include NumPy (for numerical computing), pandas (for data manipulation), Matplotlib (for visualization), and TensorFlow (a machine learning platform).
       </p>
      <p>
        The increasing complexity of a complete HEP data analysis workflow, possibly interactive, can benefit from highly parallel computing. This can be accomplished within a Python-based framework properly dealing with the standard ROOT format common to all HEP data. With reference to a representative HEP workflow taken as use case and run in a Jupyter framework, we compare the performances of Uproot (a library for reading and writing ROOT files in pure Python and NumPy) and of RDataFrame (the newest ROOT's high-level interface for an efficient data analysis task) by running on multiple CPUs.
      </p>
      <p>
        Specifically we measure the total runtime of the sequence of the following operations: 
        1) accessing the TTree inside the input ROOT files,
        2) applying specific filters (selection criteria) on the variables stored in the TTree, in order to extract a known physical signal associated to the decay chain of a beauty meson (B0s → J/psi phi, J/psi→mumu, phi→KK);
        3) converting the TBranch containing the selected invariant mass to a NumPy array for further analysis task       (signal fitting, etc ...).
      </p>
    </article>

    <article property="abstract">
      <header>
        <h3>Data</h3>
      </header>

      <p>
        The ROOT files used in our measurements, which contain 457860912 events and take up more than 128GB of disk
        space in total, were taken from CMS Run 2 dataset.
      </p>

      <p>
        For reasons that will be specified later, we split the original data set into 128 files with approximately the
        same size.
      </p>
    </article>

    <article property="abstract">
      <header>
        <h3>Computing resources</h3>
      </header>

      <p>
        Measurements were run on three different machines on the ReCaS-Bari computing center:
      </p>

      <ol>
        <li>
          <strong>wn-gpu-8-3-22</strong> (256 CPUs, 2003 GB RAM)
        </li>
        <li>
          <strong>wn-1-8-9</strong> (64 CPUs, 251GB RAM)
        </li>
        <li>
          <strong>tesla04</strong> (32 CPUs, 251 GB RAM)
        </li>
      </ol>

      <p>
        For the first two machines, data could only be stored remotely on the computing cluster, while on
        <strong>tesla04</strong>, it
        was also possible to access the data on the local disk.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>Analysis task</h3>
      </header>

      <p>
        With Uproot and RDataFrame, we measured the total runtime of the following operations:
      </p>

      <ol>
        <li>
          Accessing the TTree’s in the ROOT files.
        </li>
        <li>
          Applying specific filters (selection criteria) on the data to expose the signal of the B0s meson decaying into
          the J/psi meson (decaying into two muons) and the Phi meson (decaying into two tracks with Kaon mass
          assigned).
        </li>
        <li>
          Converting the TBranch containing the mass to a NumPy array.
        </li>
      </ol>

    </article>

    <article property="abstract">
      <header>
        <h3>Analysis task</h3>
      </header>


      <figure>
        <img src="plots/dist1.png">
      </figure>
      <figure>
        <img src="plots/dist2.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Setup</h3>
      </header>

      <p>
        To take advantage of our multi-core computers, we adopted parallel processing in our measurement. In other
        words, instead of letting one CPU handle the whole dataset, we used multiple CPUs running in parallel to process
        pieces of data concurrently.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>Uproot</h3>
      </header>

      <p>
        With Uproot, there isn’t a built-in option for implicit parallel processing. To enable parallelism, therefore,
        we manually created subprocesses with Python’s multiprocessing module. Since Uproot allows users to specify the
        number of events to be processed in each TTree, the smallest unit of data distributed to each subprocess is one
        event. As a result, the workload can always be divided equally among subprocesses.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>RDataFrame</h3>
      </header>

      <p>
        RDataFrame, on the other hand, has a built-in option for implicit parallelism: EnableImplicitMT(). However, it
        appears to work inconsistently on different machines and different ROOT versions.
      </p>

      <figure>
        <img src="plots/implicitmt1.png">
      </figure>
      <figure>
        <img src="plots/implicitmt3.png">
      </figure>
      <figure>
        <img src="plots/implicitmt2.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>RDataFrame</h3>
      </header>

      <p>
        Alternatively, we followed the same approach mentioned above: explicitly creating subprocesses to handle pieces
        of data. Unlike Uproot,
        RDataFrame doesn’t provide the option to specify the number of events to be processed in each file, so the
        smallest unit of data distributed to each subprocess is one
        file. As a result, each subprocess will work on
        approximately the same number of files rather than the same number of events.
      </p>

      <p>
        To make it easier to distribute data evenly with RDataFrame, we split – by using Uproot – the original dataset
        into 128 files, each containing the
        same number of events. For a fair comparison, we used these files as input for both Uproot and RDataFrame.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/rvp1.png">
      </figure>
      <figure>
        <img src="plots/rvp2.png">
      </figure>
      <figure>
        <img src="plots/rvp3.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/svp1.png">
      </figure>
      <figure>
        <img src="plots/svp2.png">
      </figure>
      <figure>
        <img src="plots/svp3.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/rvs1.png">
      </figure>
      <figure>
        <img src="plots/rvs2.png">
      </figure>
      <figure>
        <img src="plots/rvs3.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/localvsremote1.png">
      </figure>
      <figure>
        <img src="plots/localvsremote2.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Conclusion</h3>
      </header>

      <p>
        By enabling parallelism, we effectively optimized the performance of both Uproot and RDataFrame. While Uproot
        ran faster at fewer processes, RDataFrame got better performance as the number of processes increased. This may
        suggest that on machines with a lot of CPUs, it is more beneficial to use the latter. However, we must keep in
        mind that RDataFrame was able to reach such a great performance because the original dataset was divided into
        many small files with the same number of events. In real-life situations, such condition is not guaranteed, so
        Uproot may still be the better choice.
      </p>

    </article>

    <!-- <figure style="flex-grow: 9999999">
      <img style="width: 70%" src="logo.svg" alt="Project logo" />
      <figcaption>A stand-alone figure to fill the remaining space.</figcaption>
    </figure> -->
  </main>

  <!-- <footer>
    <address class="monospace"> <a
        href="https://github.com/cpitclaudel/academic-poster-template">https://github.com/cpitclaudel/academic-poster-template</a>
    </address>
    <address class="monospace"> clement.pitclaudel@live.com
    </address>
    <span class="credits">
      Based on an <a href="https://github.com/cpitclaudel/academic-poster-template">open poster template</a>.
    </span>
  </footer> -->
</body>

</html>
